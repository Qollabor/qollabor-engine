##################################################################################################
##                                                                                              ##
## Default configurations to use                                                                ##
##   - Cassandra for storing events                                                             ##
##   - PostgreSQL for building up projections database for case queries                         ##
##                                                                                              ##
##  Specific settings are passed as environment variables                               ##
##                                                                                              ##
##################################################################################################
akka {
  loglevel = DEBUG
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logger-startup-timeout = 10s

  actor {
    serialize-messages = on

    serializers {
      qollabor_serializer = "org.qollabor.akka.actor.serialization.QollaborSerializer"
    }

    serialization-bindings {
      "org.qollabor.akka.actor.serialization.QollaborSerializable" = qollabor_serializer
    }
  }

  persistence {
    journal {
      # DO NOT USE LEVELDB FOR A MULTI NODE SETUP !!!
      # NOTE: Default journal is leveldb, as it comes out of the box without setup.
      # However, this cannot be used in production or in a multi-node setup.
      # In that case, the cassandra-journal has to be enabled.
      #plugin = "akka.persistence.journal.leveldb"
      plugin = "cassandra-journal"
      auto-start-journals = ["cassandra-journal"]

      # Default configuration for leveldb storage of events.
      # Cassandra configuration is at the end of this file
      leveldb {
        store {
          # DO NOT USE 'native = off' IN PRODUCTION !!!
          native = off
          dir = "journal"
        }

        event-adapters {
          tagging = "org.qollabor.akka.actor.tagging.CaseTaggingEventAdapter"
        }

        event-adapter-bindings {
          "org.qollabor.akka.actor.event.ModelEvent" = tagging
        }
      }
    }

    snapshot-store {
      # Path to the snapshot store plugin to be used
      plugin = cassandra-snapshot-store
      #plugin = "akka.persistence.snapshot-store.local"

      # Local filesystem snapshot store plugin.
      local {

        # Class name of the plugin.
        class = "akka.persistence.snapshot.local.LocalSnapshotStore"

        # Dispatcher for the plugin actor.
        plugin-dispatcher = "akka.persistence.dispatchers.default-plugin-dispatcher"

        # Dispatcher for streaming snapshot IO.
        stream-dispatcher = "akka.persistence.dispatchers.default-stream-dispatcher"

        # Storage location of snapshot files.
        dir = "snapshots"
      }
    }
  }
}

qollabor {
  # Engine wide platform settings
  platform {
    # Platform has owners that are allowed to create/disable/enable tenants
    #  This property specifies the set of user-id's that are owners
    #  This array may not be empty.
    owners = ["admin"]
    owners = ${?QOLLABOR_PLATFORM_OWNERS}
    # Default tenant will be used when a user does not provide the tenant as a parameter to
    #  the API call (e.g. in StartCase). When the user is member of only one tenant,
    #  then that tenant will be submitted along with the StartCase command.
    #  If the user belongs to multiple tenants, then this default-tenant option will be passed.
    default-tenant = "world"
    default-tenant = ${?QOLLABOR_PLATFORM_DEFAULT_TENANT}
    # bootstrap-file holds a reference to a json or yaml file that has default tenant information.
    #  E.g., tenant name, tenant owners, tenant users can be given in this file.
    #  During launch of the case engine, the file will be scanned and a special CreateTenant command is sent
    #  into the system, thereby setting up a default tenant with owners and users.
    #  The bootstrap configuration will search for this file, and try to parse it into a standard akka Config
    #  object.
    # If the bootstrap-file property is not filled, the system will search for a file that holds
    #  the default tenant name plus either a .conf, .json, .yml or .yaml extension.
    #  In case of tenant 'world', the system would search for existence in the following order:
    #  - 'world.conf'
    #  - 'world.json'
    #  - 'world.yml'
    #  - 'world.yaml'
    # If none of these files are found, the bootstrap attempt will be skipped.
    bootstrap-file = "bootstrap/world.tenant.conf"
  }

  api {
    bindhost = "0.0.0.0"
    bindport = 2027

    security {
      # configuration settings for OpenID Connect
      oidc {
        ##################################################################################
        ##  Below settings can be used to configure to the untrustworthy token service  ##
        ##   Only use this to run the Qollabor Testscript Framework for test purposes.  ##
        ##   Never use this in production systems.                                      ##
        ##################################################################################
        connect-url = "http://localhost:2377/.well-known/openid-configuration"
        token-url = "http://localhost:2377/token"
        key-url = "http://localhost:2377/keys"
        authorization-url = "http://localhost:2377/auth"
        issuer = "Qollabor Test Framework"
      }

      # The subject of a valid JWT token is used to query the corresponging registered platform user from the database.
      # These identities can be cached to avoid repeated queries and thereby improve throughput times.
      # The size of the cache can be set here, it defaults to 1000
      # The cache is disabled if size is 0 or a negative number.
      identity.cache.size = 1000

      ###################################################################################################
      ##                                                                                               ##
      ## Fill this setting to true to allow developers to access engine events without authentication  ##
      ##                                                                                               ##
      ##   WARNING - Enabling opens up the full engine in read-only mode for anyone to access          ##
      ##                                                                                               ##
      ###################################################################################################
      debug.events.open = false
      debug.events.open = ${?QOLLABOR_DEBUG_EVENTS}
    }
  }

  # The case engine supports various ways to list, load and deploy case definitions.
  # The below settings can be used to configure various options; default settings use
  # a file based definition provider.
  # An alternative is to use the StartCaseDefinitionProvider, in which
  # case definitions must be passed along with the StartCase REST API itself.
  #
  # The case engine reads definitions as XML files from disk and/or the classpath.
  # The files are cached in-memory, based on their lastModified timestamp
  # (i.e., if you change a file on disk, the engine will reload it into the cache).
  # By default, the engine will read from the configured location. If the definitions file cannot be found
  # in this location, the engine will try to load it as a resource from the classpath, hence enabling to ship
  # fixed definitions in a jar file.
  definitions {
    # Default provider is based on reading/writing from the local file system
    provider = "org.qollabor.cmmn.repository.file.FileBasedDefinitionProvider"
    location = "./definitions"
    location =  ${?QOLLABOR_CMMN_DEFINITIONS_PATH}
    cache {
      size = 100
    }

    # Use the below provider to start cases while passing the definition along the StartCase call
    #  Note that the StartCaseDefinitionProvider also makes use of the same cache settings
    # provider = "org.qollabor.cmmn.repository.StartCaseDefinitionProvider"
  }

  actor {
    # the seconds of idle time after which a case actor is removed from akka memory
    # if the case has not received new commands after the specified number of seconds,
    # the case engine will ask akka to remove the case from memory to avoid memory leaks.
    idle-period = 600

    # If debug is true, then all StartCase commands by default will run in debug mode,
    #  unless specified otherwise in the command
    debug = false
  }

  timer-service {
    # The number of seconds that the TimerService should wait to persist it's snapshot
    # after a timer has occurred or has been canceled.
    # Note: for setting timers always immediately snapshots are stored
    persist-delay = 60
  }

  # This setting tells qollabor which journal to use for reading events.
  #  If omitted, qollabor will try to guess the read journal, based on the akka settings
  read-journal = "cassandra-query-journal"

  query-db {
    profile = "slick.jdbc.PostgresProfile$"
    profile = ${?PROJECTION_DB_PROFILE}
    db {
      driver = "org.postgresql.Driver"
      driver =  ${?PROJECTION_DB_DRIVER}
      ###################################################################
      ##                                                               ##
      ##  Database schema 'qollabor-query' must be created manually    ##
      ##                                                               ##
      ###################################################################
      url = ""
      url =  ${PROJECTION_DB_URL}

      ###################################################################
      ##                                                               ##
      ##  MAKE SURE TO FILL USER AND PASSWORD FOR CONNECTION           ##
      ##                                                               ##
      ###################################################################
      user = "postgresuser"
      user =  ${?PROJECTION_DB_USER}
      password = "mysecret"
      password =  ${?PROJECTION_DB_PASSWORD}
      numThreads = 10
      connectionTimeout = 5000
      validationTimeout = 5000
    }
  }
}

####################################################################################
##                                                                                ##
##  Below are settings for Akka Event Storage for Cassandra                       ##
##                                                                                ##
####################################################################################
cassandra-journal {

  event-adapters {
    tagging = "org.qollabor.akka.actor.tagging.CaseTaggingEventAdapter"
  }

  event-adapter-bindings {
    "org.qollabor.akka.actor.event.ModelEvent" = tagging
  }

  events-by-tag {
    query-plugin = cassandra-query-journal
  }

  # FQCN of the cassandra journal plugin
  class = "akka.persistence.cassandra.journal.CassandraJournal"

  # Comma-separated list of contact points in the Cassandra cluster.
  # Host:Port pairs are also supported. In that case the port parameter will be ignored.
  contact-points = [${CS_HOST}]

  # Port of contact points in the Cassandra cluster.
  # Will be ignored if the contact point list is defined by host:port pairs.
  port = 9042

  # The implementation of akka.persistence.cassandra.SessionProvider
  # is used for creating the Cassandra Session. By default the 
  # the ConfigSessionProvider is building the Cluster from configuration properties
  # but it is possible to replace the implementation of the SessionProvider
  # to reuse another session or override the Cluster builder with other
  # settings.
  # For example, it is possible to lookup the contact points of the Cassandra cluster
  # asynchronously instead of giving them in the configuration in a subclass of
  # ConfigSessionProvider and overriding the lookupContactPoints method.
  # It may optionally have a constructor with an ActorSystem and Config parameter.
  # The config parameter is this config section of the plugin.
  session-provider = akka.persistence.cassandra.ConfigSessionProvider

  # The identifier that will be passed as parameter to the
  # ConfigSessionProvider.lookupContactPoints method. 
  cluster-id = ""

  # Name of the keyspace to be created/used by the journal
  keyspace = "akka"

  # Parameter indicating whether the journal keyspace should be auto created
  keyspace-autocreate = true

  # Parameter indicating whether the journal tables should be auto created
  tables-autocreate = true

  # The number of retries when a write request returns a TimeoutException or an UnavailableException.
  write-retries = 3

  # Deletes are achieved using a metadata entry and then the actual messages are deleted asynchronously
  # Number of retries before giving up
  delete-retries = 3

  # Number of retries before giving up connecting for the initial connection to the Cassandra cluster
  connect-retries = 3

  # Delay between connection retries, for the initial connection to the Cassandra cluster
  connect-retry-delay = 30s

  # Max delay of the ExponentialReconnectionPolicy that is used when reconnecting
  # to the Cassandra cluster
  reconnect-max-delay = 30s

  # Cassandra driver connection pool settings
  # Documented at https://datastax.github.io/java-driver/manual/pooling/
  connection-pool {

    # Create new connection threshold local
    new-connection-threshold-local = 800

    # Create new connection threshold remote
    new-connection-threshold-remote = 200

    # Connections per host core local
    connections-per-host-core-local = 1

    # Connections per host max local
    connections-per-host-max-local = 4

    # Connections per host core remote
    connections-per-host-core-remote = 1

    # Connections per host max remote
    connections-per-host-max-remote = 4

    # Max requests per connection local
    max-requests-per-connection-local = 32768

    # Max requests per connection remote
    max-requests-per-connection-remote = 2000

    # Sets the timeout when trying to acquire a connection from a host's pool
    pool-timeout-millis = 0
  }

  # Name of the table to be created/used by the journal.
  # If the table doesn't exist it is automatically created.
  table = "messages"

  # Compaction strategy for the journal table.
  # Please refer to the tests for example configurations.
  # Refer to http://docs.datastax.com/en/cql/3.1/cql/cql_reference/compactSubprop.html 
  # for more information regarding the properties.
  table-compaction-strategy {
    class = "SizeTieredCompactionStrategy"
  }

  # Name of the table to be created/used for storing metadata.
  # If the table doesn't exist it is automatically created.
  metadata-table = "metadata"

  # Name of the table to be created/used for journal config.
  # If the table doesn't exist it is automatically created.
  config-table = "config"

  # Set this to on to only use Cassandra 2.x compatible features,
  # i.e. if you are using a Cassandra 2.x server.
  # To run tests with Cassandra 2.x server you have to do the following:
  # - start Cassandra 2.x server on default port 9042, with empty data directory
  # - change CassandraLauncher.randomPort to 9042
  # - change CassandraLauncher.start to do nothing
  # - set this cassandra-2x-compat = on
  # - note that you must delete all data between each test run
  cassandra-2x-compat = off

  # Possibility to disable the eventsByTag query and creation of
  # the materialized view. This will automatically be off when
  # cassandra-2x-compat=on 
  enable-events-by-tag-query = on

  # Name of the materialized view for eventsByTag query
  events-by-tag-view = "eventsbytag"

  # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
  replication-strategy = "SimpleStrategy"

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  data-center-replication-factors = []

  # To limit the Cassandra hosts this plugin connects with to a specific datacenter.
  # (DCAwareRoundRobinPolicy withLocalDc)
  # The id for the local datacenter of the Cassandra hosts it should connect to. 
  # By default, this property is not set resulting in Datastax's standard round robin policy being used.
  local-datacenter = ""

  # Number of hosts from non-local datacenter to use as a fall-back policy.
  # Works only when local-datacenter is set
  used-hosts-per-remote-dc = 0

  # To connect to the Cassandra hosts with credentials.
  # Authentication is disabled if username is not configured.
  authentication.username = ""
  authentication.password = ""

  # SSL can be configured with the following properties.
  # SSL is disabled if the truststore is not configured.
  # For detailed instructions, please refer to the DataStax Cassandra chapter about 
  # SSL Encryption: http://docs.datastax.com/en/cassandra/2.0/cassandra/security/secureSslEncryptionTOC.html
  # Path to the JKS Truststore file 
  ssl.truststore.path = ""
  # Password to unlock the JKS Truststore
  ssl.truststore.password = ""
  # Path to the JKS Keystore file (optional config, only needed for client authentication)
  ssl.keystore.path = ""
  # Password to unlock JKS Truststore and access the private key (both must use the same password)
  ssl.keystore.password = ""

  # Write consistency level
  # The default read and write consistency levels ensure that persistent actors can read their own writes.
  # During normal operation, persistent actors only write to the journal, reads occur only during recovery.
  write-consistency = "QUORUM"

  # Read consistency level
  read-consistency = "QUORUM"

  # Maximum number of messages that will be batched when using `persistAsync`. 
  # Also used as the max batch size for deletes.
  max-message-batch-size = 100

  # Target number of entries per partition (= columns per row).
  # Must not be changed after table creation (currently not checked).
  # This is "target" as AtomicWrites that span partition boundaries will result in bigger partitions to ensure atomicity.
  target-partition-size = 500000

  # Maximum size of result set
  max-result-size = 50001

  # Maximum size of result set during replay
  max-result-size-replay = 50001

  # The query journal to use when recoverying
  query-plugin = "cassandra-query-journal"

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "cassandra-plugin-default-dispatcher"

  # Dispatcher for potentially blocking tasks.
  blocking-dispatcher = "cassandra-plugin-blocking-dispatcher"

  # The time to wait before cassandra will remove the thombstones created for deleted entries.
  # cfr. gc_grace_seconds table property documentation on http://www.datastax.com/documentation/cql/3.1/cql/cql_reference/tabProp.html
  gc-grace-seconds = 864000

  # When using more than one tag per event you have to configure know 
  # tags in this section to give each tag an identifier. When using 
  # only one tag per event the identifier is 1, automatically.
  # tagname = tagid
  # where tagid must be 1, 2, or 3. Max 3 tags per event is supported.
  # For example:
  #   BlogPosts = 1
  #   Announcement = 2
  #   Authors = 1
  # With those tag identifiers you can use BlogPosts and Announcement for a single event,
  # but you cannot combine BlogPosts and Authors, since they have the same tag identifier.  
  tags {
  }

  # Minimum time between publishing messages to DistributedPubSub to announce events for a specific tag have
  # been written. These announcements cause any ongoing getEventsByTag to immediately re-poll, rather than
  # wait. In order enable this feature, make the following settings:
  #  
  #    - enable clustering for your actor system
  #    - cassandra-journal.pubsub-minimum-interval = 1s              (send real-time announcements at most every sec)
  #    - cassandra-query-journal.eventual-consistency-delay = 0s     (so it immediately tries to show changes)
  #
  # Setting pubsub-minimum-interval to "off" will disable the journal sending these announcements. 
  pubsub-minimum-interval = off

  # Set the protocol version explicitly, should only be used for compatibility testing.
  # Supported values: 3, 4
  protocol-version = ""
}

# This configures the default settings for all CassandraReadJournal plugin
# instances in the system.
#
# If you use multiple plugin instances you need to create differently named 
# sections containing only those settings that shall be different from the defaults
# configured here, importing the defaults like so:
#
#   my-cassandra-query-journal = ${cassandra-query-journal}
#   my-cassandra-query-journal {
#     <settings...>
#   }
cassandra-query-journal {
  # Implementation class of the Cassandra ReadJournalProvider
  class = "akka.persistence.cassandra.query.CassandraReadJournalProvider"

  # Absolute path to the write journal plugin configuration section
  write-plugin = "cassandra-journal"

  # New events are retrieved (polled) with this interval.
  refresh-interval = 1s

  # How many events to fetch in one query (replay) and keep buffered until they
  # are delivered downstreams.
  max-buffer-size = 500

  # The fetch size of the Cassandra select statement
  # Value less or equal to 0 means max-result-size will be used
  # http://docs.datastax.com/en/drivers/java/3.0/com/datastax/driver/core/Statement.html
  max-result-size-query = 250

  # Read consistency level
  read-consistency = "QUORUM"

  # The number of retries when a read query fails.
  read-retries = 3

  # Configure this to the first bucket eventByTag queries will start from in the format
  # yyyyMMddTHH:mm yyyyMMdd is also supported if using Day as a bucket size
  # Will be rounded down to the start of whatever time bucket it falls into
  # When NoOffset is used it will look for events from this day and forward.
  # First time bucket dramatically improves startup performance if projections starts freshly with NoOffset
  first-time-bucket = "20200101T00:00"

  session-provider = "akka.cassandra.session.DefaultSessionProvider"
  session-name = ""

  # Absolute path to the write journal plugin configuration section
  write-plugin = "cassandra-journal"
  read-profile = "cassandra-journal"

  # NOTE: Setting refresh-interval to less than 2 seconds is not recommended.
  refresh-interval = 100ms

  events-by-tag {
    refresh-interval = 100ms
    # Setting this to anything lower than 2s is highly discouraged.
    # In a developer system for just dev&test it is fine.
    eventual-consistency-delay = 100ms
  }

  # The returned event stream is ordered by the offset (timestamp), which corresponds
  # to the same order as the write journal stored the events, with inaccuracy due to clock skew
  # between different nodes. The same stream elements (in same order) are returned for multiple
  # executions of the query on a best effort basis. The query is using a Cassandra Materialized
  # View for the query and that is eventually consistent, so different queries may see different
  # events for the latest events, but eventually the result will be ordered by timestamp
  # (Cassandra timeuuid column). To compensate for the the eventual consistency the query is
  # delayed to not read the latest events, the duration of this delay is defined by this 
  # configuration property.
  # However, this is only best effort and in case of network partitions
  # or other things that may delay the updates of the Materialized View the events may be
  # delivered in different order (not strictly by their timestamp).  
  eventual-consistency-delay = 1s

  # If you use the same tag for all events for a `persistenceId` it is possible to get
  # a more strict delivery order than otherwise. This can be useful when all events of
  # a PersistentActor class (all events of all instances of that PersistentActor class)
  # are tagged with the same tag. Then the events for each `persistenceId` can be delivered
  # strictly by sequence number. If a sequence number is missing the query is delayed up 
  # to the configured `delayed-event-timeout` and if the expected event is still not 
  # found the stream is completed with failure. This means that there must not be any 
  # holes in the sequence numbers for a given tag, i.e. all events must be tagged
  # with the same tag. Set this property to for example 30s to enable this feature.
  # It is disabled by default.
  delayed-event-timeout = 0s

  # Dispatcher for the plugin actors.
  plugin-dispatcher = "cassandra-plugin-default-dispatcher"
}

cassandra-snapshot-store {

  # FQCN of the cassandra snapshot store plugin
  class = "akka.persistence.cassandra.snapshot.CassandraSnapshotStore"

  # Comma-separated list of contact points in the cluster
  contact-points = [${CS_HOST}]

  # Port of contact points in the cluster
  port = 9042

  # Name of the keyspace to be created/used by the snapshot store
  keyspace = "akka_snapshot"

  # Parameter indicating whether the snapshot keyspace should be auto created
  keyspace-autocreate = true

  # In case that schema creation failed you can define a number of retries before giving up.
  keyspace-autocreate-retries = 1

  # Number of retries before giving up connecting to the cluster
  connect-retries = 3

  # Delay between connection retries
  connect-retry-delay = 5s

  # Name of the table to be created/used by the snapshot store
  table = "snapshots"

  # Compaction strategy for the snapshot table
  table-compaction-strategy {
    class = "SizeTieredCompactionStrategy"
  }

  # Name of the table to be created/used for journal config
  config-table = "config"

  # Name of the table to be created/used for storing metadata
  metadata-table = "metadata"

  # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
  replication-strategy = "SimpleStrategy"

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  data-center-replication-factors = []

  # Write consistency level
  write-consistency = "ONE"

  # Read consistency level
  read-consistency = "ONE"

  # Maximum number of snapshot metadata to load per recursion (when trying to
  # find a snapshot that matches specified selection criteria). Only increase
  # this value when selection criteria frequently select snapshots that are
  # much older than the most recent snapshot i.e. if there are much more than
  # 10 snapshots between the most recent one and selected one. This setting is
  # only for increasing load efficiency of snapshots.
  max-metadata-result-size = 10

  # Maximum size of result set
  max-result-size = 50001

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "cassandra-snapshot-store.default-dispatcher"

  # Default dispatcher for plugin actor.
  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 8
    }
  }
}
